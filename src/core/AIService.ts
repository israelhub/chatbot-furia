/**
 * Servi√ßo de Intelig√™ncia Artificial para o FuriaBot
 * Respons√°vel pela integra√ß√£o com modelos de linguagem avan√ßados
 * Suporta m√∫ltiplos provedores de IA
 */
import axios from 'axios';
import { ISimpleCache, AIServiceConfig, AIProvider, AIRequestPayload, IDataProvider } from '../types/index.js';

// ======================================================================
// CONFIGURA√á√ïES PADR√ÉO DO SERVI√áO DE IA 
// Modifique estas constantes para alterar o comportamento padr√£o
// ======================================================================
const DEFAULT_CONFIG: AIServiceConfig = {
  provider: AIProvider.GEMINI,
  apiKey: "",
  endpoint: "",
  model: "gemini-2.0-flash",
  contextMemorySize: 5,
  defaultTemperature: 0.7,
  maxTokens: 300,
  useCache: true,
  cacheTTL: 3600 * 24 // 24 horas
};

// Mapeamento de modelos recomendados para cada provedor
// Adicione novos modelos aqui conforme necess√°rio
const MODEL_MAP = {
  [AIProvider.OPENAI]: ["gpt-3.5-turbo", "gpt-4", "gpt-4o"],
  [AIProvider.HUGGINGFACE]: ["meta-llama/Llama-2-7b-chat-hf", "mistralai/Mistral-7B-Instruct-v0.2"],
  [AIProvider.GEMINI]: ["gemini-2.0-flash", "gemini-2.0-pro"],
  [AIProvider.OLLAMA]: ["llama2", "mistral", "gemma"],
  [AIProvider.MOCK]: ["mock-model"] // Adicionando provedor MOCK
};

// Mapeamento de endpoints padr√£o para cada provedor
const ENDPOINT_MAP = {
  [AIProvider.OPENAI]: 'https://api.openai.com/v1/chat/completions',
  [AIProvider.HUGGINGFACE]: 'https://api-inference.huggingface.co/models/',
  [AIProvider.GEMINI]: 'https://generativelanguage.googleapis.com/v1beta/models/',
  [AIProvider.OLLAMA]: 'http://localhost:11434/api/generate',
  [AIProvider.MOCK]: 'http://localhost:0000/mock' // Adicionando endpoint mock
};

export class AIService {
  private cacheService: ISimpleCache | null = null;
  private conversationHistory: string[] = [];
  private config: AIServiceConfig;
  private dataProvider: IDataProvider | null = null;
  
  constructor(config: Partial<AIServiceConfig> = {}) {
    // Inicia com as configura√ß√µes padr√£o sem depend√™ncia do CONFIG
    this.config = { ...DEFAULT_CONFIG, ...config };
    
    console.log(`ü§ñ AIService inicializado usando provedor: ${this.config.provider}`);
  }
  
  /**
   * M√©todo para atualizar a configura√ß√£o da IA com os valores do CONFIG
   * Este m√©todo deve ser chamado ap√≥s a inicializa√ß√£o para evitar depend√™ncia circular
   */
  public updateConfig(config: Partial<AIServiceConfig>): void {
    this.config = { ...this.config, ...config };
    console.log(`üîÑ AIService reconfigurado: ${this.config.provider}, modelo: ${this.config.model}`);
  }
  
  /**
   * M√©todo para injetar o servi√ßo de cache ap√≥s a inicializa√ß√£o
   * Isso evita a depend√™ncia circular
   */
  public setCacheService(cacheService: ISimpleCache): void {
    this.cacheService = cacheService;
  }
  
  /**
   * M√©todo para injetar o provedor de dados ap√≥s a inicializa√ß√£o
   * Isso evita a depend√™ncia circular
   */
  public setDataProvider(dataProvider: IDataProvider): void {
    this.dataProvider = dataProvider;
    console.log('üìä DataProvider configurado no AIService');
  }
  
  /**
   * Retorna o endpoint padr√£o baseado no provedor
   */
  public getDefaultEndpoint(provider?: AIProvider): string {
    const useProvider = provider || this.config.provider;
    return ENDPOINT_MAP[useProvider] || ENDPOINT_MAP[AIProvider.GEMINI];
  }
  
  /**
   * Retorna o modelo padr√£o baseado no provedor
   */
  public getDefaultModel(provider?: AIProvider): string {
    const useProvider = provider || this.config.provider;
    const models = MODEL_MAP[useProvider] || MODEL_MAP[AIProvider.GEMINI];
    return models[0]; // Retorna o primeiro modelo na lista (o recomendado)
  }

  /**
   * Retorna os modelos dispon√≠veis para um provedor espec√≠fico
   * √ötil para interfaces que permitem sele√ß√£o de modelo
   */
  public getAvailableModels(provider?: AIProvider): string[] {
    const useProvider = provider || this.config.provider;
    return MODEL_MAP[useProvider] || [];
  }
  
  /**
   * Gera uma resposta utilizando IA com base na pergunta do usu√°rio
   */
  public async generateResponse(userQuery: string, context?: string): Promise<string> {
    const cacheKey = `ai_response:${userQuery}`;
    
    // Verifica se h√° resposta em cache (se o cache estiver dispon√≠vel)
    if (this.config.useCache && this.cacheService) {
      const cachedResponse = this.cacheService.getCachedData(cacheKey) as string;
      if (cachedResponse) {
        console.log(`üß† Usando resposta em cache para: "${userQuery.substring(0, 30)}..."`);
        return cachedResponse;
      }
    }
    
    try {
      // Mant√©m hist√≥rico da conversa para contexto
      this.updateConversationHistory(userQuery);
      
      // Prepara o contexto para a IA incluindo dados sobre a FURIA
      console.log('Context adicional recebido:', context);
      
      // Se o context j√° contiver dados, vamos evitar duplica√ß√£o
      const enrichedContext = await this.prepareContext(context);
      
      // Chama a API de IA
      const prompt = this.buildPrompt(userQuery, enrichedContext);
      
      // Verifica se h√° dados duplicados com r√≥tulos em ingl√™s
      if (prompt.includes('PLAYERS:') || prompt.includes('RESULTS:') || 
          prompt.includes('HISTORY:') || prompt.includes('LASTMATCH:')) {
        console.warn('‚ö†Ô∏è Detectada poss√≠vel duplica√ß√£o de dados no prompt com r√≥tulos em ingl√™s');
      }
      
      const response = await this.callAIAPI({
        prompt,
        maxTokens: this.config.maxTokens,
        temperature: this.config.defaultTemperature
      });
      
      // Formata e valida a resposta
      const formattedResponse = this.formatResponse(response);
      
      // Atualiza o hist√≥rico com a resposta
      this.updateConversationHistory(formattedResponse, false);
      
      // Armazena em cache (se o cache estiver dispon√≠vel)
      if (this.config.useCache && this.cacheService) {
        this.cacheService.setCachedData(cacheKey, formattedResponse, this.config.cacheTTL);
      }
      
      return formattedResponse;
    } catch (error) {
      console.error('Erro ao gerar resposta com IA:', error);
      // Fallback para m√©todo tradicional em caso de erro
      return this.generateFallbackResponse(userQuery);
    }
  }
  
  // ======================================================================
  // CUSTOMIZA√á√ÉO DO PROMPT - PERSONALIZE AQUI
  // Modifique esta fun√ß√£o para ajustar o comportamento do bot
  // ======================================================================
  private buildPrompt(userQuery: string, context: string): string {
    // Adicionando log do contexto completo para depura√ß√£o
    console.log('üß† Contexto completo enviado para IA:', context);
    
    return `Voc√™ √© um BOT oficial da equipe FURIA de CS:GO. Use linguagem casual e amig√°vel, com estilo amistoso de f√£. Evite ser muito aleat√≥rio.
    
Contexto sobre a FURIA para suas respostas:
${context}

Hist√≥rico de conversa:
${this.conversationHistory.join('\n')}

Regras importantes:
1. Priorize informa√ß√µes do contexto fornecido
2. Seja preciso ao falar sobre jogadores, partidas e hist√≥ria da FURIA
3. Use emojis üêæ e üî• ocasionalmente para representar a FURIA
4. Se voc√™ n√£o souber a resposta com base no contexto, diga que n√£o tem essa informa√ß√£o no momento
5. Mantenha respostas concisas (m√°ximo 3-4 par√°grafos)
6. N√£o invente informa√ß√µes que n√£o estejam no contexto
7. Lembre-se que o usu√°rio pode usar comandos iniciando com "/" para acessar informa√ß√µes espec√≠ficas, para saber todos os comandos pode usar "/ajuda"
8. Quando se referir ao usu√°rio, use "Furioso(a)"
9. Evite usar sauda√ß√µes como "E ai", "Oi", "Ol√°", "Fala" ou "Salve" em todas as respostas, principalmente se j√° houver uma conversa anterior
10. Caso o usuario pergunte sobre a historia da furia responda exatamente o que est√° no contexto, sem adicionar mais informa√ß√µes ou fazer compara√ß√µes com outros times

Comandos dispon√≠veis:
- /ajuda - Lista todos os comandos dispon√≠veis

Pergunta do usu√°rio: ${userQuery}

Sua resposta (em portugu√™s):`;
  }
  
  /**
   * Prepara o contexto para a IA com informa√ß√µes sobre a FURIA obtidas em tempo real
   */
  private async prepareContext(additionalContext?: string): Promise<string> {
    // Verifica se o DataProvider est√° configurado
    if (!this.dataProvider) {
      console.warn('‚ö†Ô∏è DataProvider n√£o configurado no AIService. Usando contexto m√≠nimo.');
      return additionalContext || 'Sem informa√ß√µes contextuais dispon√≠veis.';
    }
    
    try {
      // Coleta dados em tempo real usando o DataProvider
      const [players, results, lastMatch, history, nextMatches] = await Promise.allSettled([
        this.dataProvider.getActivePlayers(),
        this.dataProvider.getRecentResults(),
        this.dataProvider.getLastMatch(),
        this.dataProvider.getHistory(),
        this.dataProvider.getNextMatches()
      ]);
      
      // Constr√≥i o contexto combinando todas as informa√ß√µes dispon√≠veis
      const baseContext = `
INFORMA√á√ïES SOBRE JOGADORES ATUAIS:
${players.status === 'fulfilled' ? players.value : 'Informa√ß√µes de jogadores indispon√≠veis no momento.'}

RESULTADOS RECENTES:
${results.status === 'fulfilled' ? results.value : 'Resultados recentes indispon√≠veis no momento.'}

√öLTIMO JOGO:
${lastMatch.status === 'fulfilled' ? lastMatch.value : 'Informa√ß√µes do √∫ltimo jogo indispon√≠veis no momento.'}

HIST√ìRIA DA FURIA:
${history.status === 'fulfilled' ? history.value : 'Hist√≥ria da FURIA indispon√≠vel no momento.'}

PR√ìXIMAS PARTIDAS:
${nextMatches.status === 'fulfilled' ? nextMatches.value : 'Pr√≥ximas partidas indispon√≠veis no momento.'}
`;

      return additionalContext ? `${baseContext}\n\n${additionalContext}` : baseContext;
    } catch (error) {
      console.error('Erro ao preparar contexto a partir do DataProvider:', error);
      return additionalContext || 'Contexto indispon√≠vel devido a erro na obten√ß√£o de dados.';
    }
  }
  
  /**
   * Atualiza o hist√≥rico de conversa para fornecer contexto √† IA
   */
  private updateConversationHistory(message: string, isUser: boolean = true): void {
    const formattedMessage = isUser ? `Usu√°rio: ${message}` : `Bot: ${message}`;
    this.conversationHistory.push(formattedMessage);
    
    // Limita o tamanho do hist√≥rico para n√£o exceder o contexto
    if (this.conversationHistory.length > this.config.contextMemorySize * 2) {
      // Remove as mensagens mais antigas, mantendo o par pergunta/resposta
      this.conversationHistory = this.conversationHistory.slice(2);
    }
  }
  
  // ======================================================================
  // INTEGRA√á√ïES COM PROVEDORES DE IA - ADICIONE NOVOS PROVEDORES AQUI
  // ======================================================================
  /**
   * Chama a API de IA com as configura√ß√µes adequadas, suportando m√∫ltiplas APIs
   */
  private async callAIAPI(payload: AIRequestPayload): Promise<string> {
    if (this.config.provider === AIProvider.MOCK || 
        (this.config.provider !== AIProvider.OLLAMA && !this.config.apiKey)) {
      console.log('üß™ Modo de simula√ß√£o de IA ativado');
      return this.simulateAIResponse(payload.prompt);
    }
    
    try {
      // Delega√ß√£o para o m√©todo espec√≠fico do provedor
      const providerHandlers = {
        [AIProvider.OPENAI]: this.callOpenAI.bind(this),
        [AIProvider.HUGGINGFACE]: this.callHuggingFace.bind(this),
        [AIProvider.GEMINI]: this.callGemini.bind(this),
        [AIProvider.OLLAMA]: this.callOllama.bind(this)
        // Adicione novos provedores aqui seguindo o mesmo padr√£o
      };
      
      const handler = providerHandlers[this.config.provider];
      if (!handler) {
        throw new Error(`Provedor de IA n√£o suportado: ${this.config.provider}`);
      }
      
      return handler(payload);
    } catch (error) {
      console.error(`Erro ao chamar API de IA (${this.config.provider}):`, error);
      throw error;
    }
  }
  
  /**
   * Chamada √† API da OpenAI (paga)
   */
  private async callOpenAI(payload: AIRequestPayload): Promise<string> {
    const response = await axios.post(
      this.config.endpoint || this.getDefaultEndpoint(AIProvider.OPENAI),
      {
        model: this.config.model || this.getDefaultModel(AIProvider.OPENAI),
        messages: [{ role: "user", content: payload.prompt }],
        max_tokens: payload.maxTokens,
        temperature: payload.temperature
      },
      {
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.config.apiKey}`
        },
        timeout: 10000
      }
    );
    
    return response.data.choices[0].message.content;
  }
  
  /**
   * Chamada √† API do Hugging Face (tem cota gratuita)
   */
  private async callHuggingFace(payload: AIRequestPayload): Promise<string> {
    const fullEndpoint = `${this.config.endpoint || this.getDefaultEndpoint(AIProvider.HUGGINGFACE)}${this.config.model || this.getDefaultModel(AIProvider.HUGGINGFACE)}`;
    const response = await axios.post(
      fullEndpoint,
      { inputs: payload.prompt, parameters: { temperature: payload.temperature, max_new_tokens: payload.maxTokens } },
      {
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.config.apiKey}`
        },
        timeout: 30000
      }
    );
    
    if (Array.isArray(response.data) && response.data.length > 0) {
      return response.data[0].generated_text || '';
    } else if (response.data.generated_text) {
      return response.data.generated_text;
    }
    
    return JSON.stringify(response.data);
  }
  
  /**
   * Chamada √† API do Google Gemini (tem cota gratuita)
   */
  private async callGemini(payload: AIRequestPayload): Promise<string> {
    const modelToUse = this.config.model || this.getDefaultModel(AIProvider.GEMINI);
    const fullEndpoint = `${this.config.endpoint || this.getDefaultEndpoint(AIProvider.GEMINI)}${modelToUse}:generateContent?key=${this.config.apiKey}`;
    
    console.log(`üîÑ Enviando requisi√ß√£o para Gemini - Endpoint: ${fullEndpoint.split('?key=')[0]}`);
    console.log(`üîë Chave API configurada: ${this.config.apiKey ? 'Sim (primeiros 5 caracteres: ' + this.config.apiKey.substring(0, 5) + '...)' : 'N√£o'}`);
    
    try {
      console.log(`üì§ Enviando prompt para Gemini (tamanho: ${payload.prompt.length} caracteres)`);
      
      const response = await axios.post(
        fullEndpoint,
        {
          contents: [{ 
            parts: [{ text: payload.prompt }] 
          }],
          generationConfig: {
            temperature: payload.temperature,
            maxOutputTokens: payload.maxTokens,
            topP: 0.8,
            topK: 40
          }
        },
        { 
          timeout: 30000,
          headers: {
            'Content-Type': 'application/json'
          }
        }
      );
      
      console.log(`üì• Resposta recebida do Gemini (status: ${response.status})`);
      
      if (response.data.candidates && response.data.candidates.length > 0) {
        const candidate = response.data.candidates[0];
        if (candidate.content && candidate.content.parts && candidate.content.parts.length > 0) {
          const responseText = candidate.content.parts[0].text || '';
          console.log(`‚úÖ Texto extra√≠do com sucesso (tamanho: ${responseText.length} caracteres)`);
          return responseText;
        }
      }
      
      console.error('Resposta do Gemini n√£o cont√©m o formato esperado:', JSON.stringify(response.data));
      throw new Error('Formato de resposta do Gemini inv√°lido');
    } catch (error) {
      if (axios.isAxiosError(error)) {
        console.error(`‚ùå Erro na chamada √† API do Gemini: ${error.message}`);
        if (error.response) {
          console.error('Detalhes do erro:', JSON.stringify(error.response.data));
          
          if (error.response.status === 400) {
            console.error('Poss√≠vel erro no formato da requisi√ß√£o');
          } else if (error.response.status === 401 || error.response.status === 403) {
            console.error('Problema de autentica√ß√£o - verifique sua chave API');
          } else if (error.response.status === 404) {
            console.error('Modelo n√£o encontrado - o nome do modelo pode estar incorreto');
          }
        } else if (error.request) {
          console.error('Sem resposta do servidor Gemini - poss√≠vel problema de rede ou timeout');
        }
      } else {
        console.error('Erro desconhecido ao chamar Gemini:', error);
      }
      throw error;
    }
  }
  
  /**
   * Chamada √† API do Ollama (local, gratuita)
   */
  private async callOllama(payload: AIRequestPayload): Promise<string> {
    const response = await axios.post(
      this.config.endpoint || this.getDefaultEndpoint(AIProvider.OLLAMA),
      {
        model: this.config.model || this.getDefaultModel(AIProvider.OLLAMA),
        prompt: payload.prompt,
        options: {
          temperature: payload.temperature,
          num_predict: payload.maxTokens
        }
      },
      { timeout: 30000 }
    );
    
    return response.data.response || '';
  }
  
  // ======================================================================
  // FORMATA√á√ÉO E FALLBACK DE RESPOSTAS
  // ======================================================================
  /**
   * Formata e valida a resposta da IA
   */
  private formatResponse(rawResponse: string): string {
    let response = rawResponse.trim();
    
    if (!response.includes('üêæ') && !response.includes('üî•')) {
      response += ' üêæ üî•';
    }
    
    return response;
  }
  
  /**
   * Gera uma resposta simulada para testes ou quando a API n√£o est√° dispon√≠vel
   */
  private simulateAIResponse(prompt: string): string {
    console.log('Simulando resposta da IA para prompt:', prompt.substring(0, 100) + '...');
    
    const lowerPrompt = prompt.toLowerCase();
    
    if (lowerPrompt.includes('jogadores') || lowerPrompt.includes('lineup') || lowerPrompt.includes('elenco')) {
      return `O elenco atual da FURIA conta com jogadores incr√≠veis como KSCERATO, yuurih, FalleN, molodoy e YEKINDAR. Cada um deles traz habilidades √∫nicas para o time! üêæ üî•`;
    }
    
    if (lowerPrompt.includes('√∫ltimas partidas') || lowerPrompt.includes('resultados') || lowerPrompt.includes('jogos recentes')) {
      return `Nos √∫ltimos jogos, a FURIA enfrentou desafios importantes! Tivemos algumas vit√≥rias e derrotas, com destaque para o √∫ltimo jogo contra a NAVI, que foi muito disputado. Continue acompanhando para ver a evolu√ß√£o do time! üêæ üî•`;
    }
    
    if (lowerPrompt.includes('hist√≥ria') || lowerPrompt.includes('funda√ß√£o') || lowerPrompt.includes('trajet√≥ria')) {
      return `A FURIA tem uma hist√≥ria incr√≠vel no cen√°rio de CS:GO! Fundada em 2017, a organiza√ß√£o rapidamente se destacou com seu estilo de jogo agressivo e inovador. Desde ent√£o, conquistou seu espa√ßo no cen√°rio mundial com grandes momentos em torneios importantes. A chegada de FalleN em 2023 trouxe ainda mais experi√™ncia para o time! üêæ üî•`;
    }
    
    return `Obrigado pela sua pergunta sobre a FURIA! Estamos sempre evoluindo e buscando representar o Brasil da melhor forma poss√≠vel nos torneios internacionais. Posso te ajudar com informa√ß√µes sobre jogadores, resultados recentes ou a hist√≥ria do time. O que mais voc√™ gostaria de saber? üêæ üî•`;
  }
  
  /**
   * Gera uma resposta de fallback usando o m√©todo tradicional
   */
  private async generateFallbackResponse(userQuery: string): Promise<string> {
    if (this.dataProvider) {
      try {
        if (userQuery.toLowerCase().includes('jogadores')) {
          const players = await this.dataProvider.getActivePlayers();
          return `O elenco atual da FURIA √©:\n\n${players}\n\nEsse √© o nosso esquadr√£o! üêæ üî•`;
        }
        
        if (userQuery.toLowerCase().includes('resultados')) {
          const results = await this.dataProvider.getRecentResults();
          return `Aqui est√£o os resultados recentes da FURIA no CS:GO:\n\n${results}\n\nSempre na torcida pelo nosso esquadr√£o! üêæ üî•`;
        }
        
        if (userQuery.toLowerCase().includes('hist√≥ria')) {
          const history = await this.dataProvider.getHistory();
          return `${history}\n\nSomos FURIA! üêæ üî•`;
        }
        
        if (userQuery.toLowerCase().includes('pr√≥ximo') || userQuery.toLowerCase().includes('agenda')) {
          const nextMatches = await this.dataProvider.getNextMatches();
          return `Pr√≥ximos jogos da FURIA:\n\n${nextMatches}\n\nVamos torcer juntos! üêæ üî•`;
        }
        
        if (userQuery.toLowerCase().includes('√∫ltimo jogo')) {
          const lastMatch = await this.dataProvider.getLastMatch();
          return `√öltimo jogo da FURIA:\n\n${lastMatch}\n\nSempre apoiando nosso time! üêæ üî•`;
        }
      } catch (error) {
        console.error('Erro ao gerar resposta de fallback com DataProvider:', 
          error instanceof Error ? error.message : 'Erro desconhecido');
      }
    }
    
    return 'Desculpe, estou com problemas para processar sua pergunta. Tente novamente ou pergunte sobre jogadores, resultados ou hist√≥ria da FURIA! üêæ üî•';
  }
  
  /**
   * Limpa o hist√≥rico de conversa
   */
  public clearConversationHistory(): void {
    this.conversationHistory = [];
  }
}

// Exporta uma inst√¢ncia singleton para uso global
const aiServiceInstance = new AIService();
export { aiServiceInstance as aiService };